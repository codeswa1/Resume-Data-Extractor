# src/llm_client.py
from dotenv import load_dotenv
load_dotenv()

import os
import json
import re
import time
import logging
import torch
from typing import Dict, Any, Optional
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from tenacity import retry, stop_after_attempt, wait_fixed, before_log, after_log
from .validators import normalize_email, normalize_phone, normalize_skills, to_int

# Rate limiting settings
MAX_REQUESTS_PER_MINUTE = 30  # Reduced from 60 to be more conservative
MIN_RETRY_DELAY = 5  # Minimum seconds to wait between retries
MAX_RETRY_DELAY = 120  # Maximum seconds to wait between retries
_last_request_time = 0

def _rate_limit() -> None:
    """Implement rate limiting to prevent API quota issues."""
    global _last_request_time
    current_time = time.time()
    min_interval = 60.0 / MAX_REQUESTS_PER_MINUTE
    
    if _last_request_time > 0:
        elapsed = current_time - _last_request_time
        wait_time = max(min_interval, MIN_RETRY_DELAY) - elapsed
        if wait_time > 0:
            logger.info(f"Rate limiting: waiting {wait_time:.1f} seconds before next request")
            time.sleep(wait_time)
    
    _last_request_time = time.time()

def check_api_health() -> tuple[bool, Optional[str]]:
    """
    Check if the API is healthy and configured correctly.
    Returns:
        tuple: (is_healthy: bool, error_message: Optional[str])
    """
    if not GOOGLE_API_KEY:
        return False, "GOOGLE_API_KEY not configured"
        
    try:
        models = genai.list_models()
        model_path = 'models/gemini-1.5-pro'
        if not any(model_path == str(m.name) for m in models):  # Exact match
            return False, f"{model_path} model not available"
        return True, None
    except Exception as e:
        return False, f"API health check failed: {str(e)}"

# Set up logging with more detailed formatting
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
)
logger = logging.getLogger(__name__)

class ResumeParsing(Exception):
    """Base exception for resume parsing errors."""
    pass

class APIConfigError(ResumeParsing):
    """Raised when API configuration fails."""
    pass

class ParsingError(ResumeParsing):
    """Raised when resume parsing fails."""
    pass

class ValidationError(ResumeParsing):
    """Raised when parsed data validation fails."""
    pass

# Initialize Gemini API
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    error_msg = "GOOGLE_API_KEY not found in environment (.env)"
    logger.critical(error_msg)
    raise APIConfigError(error_msg)

# Default generation config for JSON output
GENERATION_CONFIG = genai.types.GenerationConfig(
    temperature=0.0,  # Use deterministic output for consistent results
    candidate_count=1,  # Only need one response
    max_output_tokens=800,  # Plenty for JSON response
    top_p=1.0
)

# Default safety settings that won't block resume content
SAFETY_SETTINGS = [
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_NONE"
    },
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_NONE"
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_NONE"
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_NONE"
    }
]

# Configure timeout and retry settings
TIMEOUT_SECONDS = 30
DEFAULT_RETRY = google_retry.Retry(
    initial=1.0,  # Initial delay in seconds
    maximum=10.0,  # Maximum delay between retries
    multiplier=2.0,  # Delay multiplier for consecutive failures
    deadline=60.0,  # Total time to try before giving up
    predicate=google_retry.if_exception_type(
        google_exceptions.ResourceExhausted,
        google_exceptions.ServiceUnavailable,
        google_exceptions.DeadlineExceeded
    )
)

try:
    logger.info("Configuring Google Generative AI client")
    genai.configure(api_key=GOOGLE_API_KEY)
    
    # Verify API key by listing models
    try:
        models = genai.list_models()
        model_names = [model.name for model in models]
        if 'models/gemini-1.5-pro' not in model_names:  # Safe string comparison
            raise APIConfigError("gemini-1.5-pro model not available in model list")
        logger.info("Available models: %s", model_names)
    except google_exceptions.PermissionDenied as e:
        raise APIConfigError(f"Invalid API key or permissions: {str(e)}")
    except Exception as e:
        raise APIConfigError(f"Failed to list models: {str(e)}")
    
    # Initialize model once at module level
    try:
        # Using the stable Gemini 1.5 Pro model (free tier) with full model path
        model = genai.GenerativeModel('models/gemini-1.5-pro', generation_config=GENERATION_CONFIG)
        logger.info("Successfully initialized Gemini 1.5 Pro model")
    except Exception as e:
        raise APIConfigError(f"Failed to initialize model: {str(e)}")
        
except Exception as e:
    logger.critical("Critical error during API initialization", exc_info=True)
    raise APIConfigError(f"Failed to initialize Gemini API: {str(e)}")

JSON_PROMPT_TMPL = """You are a strict resume parser. Respond with JSON ONLY (no prose).
Return a single JSON object **and nothing else**. Required keys exactly:
name, email, phone, skills, exp_years, current_location, salary, notice_period

Rules for parsing:
- If a value is not found, use an empty string: ""
- name: Full name as shown in resume
- email: Extract email address if present
- phone: Only numbers and + symbol, no spaces or special chars
- skills: Comma-separated list (e.g., "python, sql, pandas"), lowercase
- exp_years: Integer number only (0 if unknown)
- current_location: City and/or country if mentioned
- salary: Current or expected salary if mentioned
- notice_period: Notice period or availability information
- Do not add any extra keys
- Format the JSON compactly without extra whitespace

Resume text:
{resume}

Remember: Return ONLY the JSON object with no additional text, markdown formatting, or explanations."""

# A helper to extract the first JSON object in a string (robust if model prints extra text)
def _extract_json(text: str) -> dict:
    """
    Extract and parse JSON from model response text.
    
    Args:
        text (str): Raw response text that should contain a JSON object
        
    Returns:
        dict: Parsed JSON object
        
    Raises:
        ParsingError: If no valid JSON object can be found or parsed
    """
    logger.debug("Attempting to extract JSON from text: %s", text[:200] + "..." if len(text) > 200 else text)
    
    # Find first "{" then try to parse progressively until a valid JSON object found
    start = text.find("{")
    if start == -1:
        error_msg = "No JSON object found in response"
        logger.error("%s: %s", error_msg, text)
        raise ParsingError(error_msg)
        
    sub = text[start:]
    # Try to balance braces naively â€” find the smallest prefix that's valid JSON
    depth = 0
    for i, ch in enumerate(sub):
        if ch == "{":
            depth += 1
        elif ch == "}":
            depth -= 1
            if depth == 0:
                candidate = sub[:i + 1]
                try:
                    json_obj = json.loads(candidate)
                    logger.debug("Successfully parsed JSON object: %s", json_obj)
                    return json_obj
                except json.JSONDecodeError as e:
                    logger.debug("Failed to parse JSON candidate: %s. Error: %s", candidate, str(e))
                    # continue scanning (could be malformed)
                    pass
                    
    # fallback: try to parse the whole response
    try:
        json_obj = json.loads(text)
        logger.debug("Successfully parsed full text as JSON: %s", json_obj)
        return json_obj
    except json.JSONDecodeError as e:
        error_msg = f"Failed to parse JSON from response: {str(e)}"
        logger.error(error_msg)
        logger.debug("Problematic text: %s", text)
        raise ParsingError(error_msg)

@retry(
    stop=stop_after_attempt(3),
    wait=wait_fixed(2),
    before=before_log(logger, logging.INFO),
    after=after_log(logger, logging.INFO),
    retry=(
        retry_if_exception_type(google_exceptions.ResourceExhausted) |
        retry_if_exception_type(google_exceptions.ServiceUnavailable) |
        retry_if_exception_type(google_exceptions.DeadlineExceeded)
    )
)
def validate_parsed_json(data: Dict[str, Any]) -> None:
    """
    Validate the structure and content of parsed JSON data.
    
    Args:
        data: Dictionary containing parsed resume data
        
    Raises:
        ValidationError: If validation fails
    """
    required_fields = {
        'name': str,
        'email': str,
        'phone': str,
        'skills': str,
        'exp_years': (int, str),  # Can be either int or str, will be normalized later
        'current_location': str,
        'salary': str,
        'notice_period': str
    }
    
    for field, expected_type in required_fields.items():
        if field not in data:
            raise ValidationError(f"Missing required field: {field}")
        
        value = data[field]
        if not isinstance(value, expected_type):
            if isinstance(expected_type, tuple):
                if not any(isinstance(value, t) for t in expected_type):
                    raise ValidationError(
                        f"Invalid type for {field}: expected {expected_type}, got {type(value)}"
                    )
            else:
                raise ValidationError(
                    f"Invalid type for {field}: expected {expected_type}, got {type(value)}"
                )

def call_llm_resume_json(resume_text: str) -> Dict[str, Any]:
    """
    Process resume text and extract structured information using Gemini API.
    
    Args:
        resume_text (str): The raw text content of the resume
        
    Returns:
        dict: Parsed resume data with normalized required fields:
            - name (str): Full name of the candidate
            - email (str): Normalized email address (username@domain.com)
            - phone (str): Normalized phone number (digits and + only)
            - skills (str): Normalized comma-separated skills (lowercase)
            - exp_years (int): Years of experience (0 if unknown)
            - current_location (str): Location information
            - salary (str): Current or expected salary information
            - notice_period (str): Notice period or availability
            
    Example:
        >>> result = call_llm_resume_json("John Doe\\nEmail: john@example.com...")
        >>> assert all(k in result for k in ["name", "email", "phone", "skills"])
        >>> assert isinstance(result["exp_years"], int)
        
    Raises:
        ValueError: If resume_text is None or not a string
        APIConfigError: If API configuration or permissions are invalid
        ParsingError: If resume parsing or JSON extraction fails
        ValidationError: If parsed data fails schema validation
    """
    logger.info("Starting resume parsing")
    
    # Check API health before proceeding
    is_healthy, error_msg = check_api_health()
    if not is_healthy:
        raise APIConfigError(f"API not healthy: {error_msg}")
    
    # Apply rate limiting
    _rate_limit()
    
    # Handle empty or invalid input gracefully
    if resume_text is None:
        error_msg = "Resume text cannot be None"
        logger.error(error_msg)
        raise ValueError(error_msg)
    if not isinstance(resume_text, str):
        error_msg = f"Invalid resume_text type: {type(resume_text)}, expected str"
        logger.error(error_msg)
        raise ValueError(error_msg)
    if not resume_text.strip():
        logger.warning("Empty resume text provided, will attempt parsing with minimal context")
        resume_text = "[Empty resume text]"
        
    if not GOOGLE_API_KEY:
        error_msg = "GOOGLE_API_KEY not found in environment"
        logger.error(error_msg)
        raise APIConfigError(error_msg)

    logger.info(f"Preparing prompt with resume text length: {len(resume_text)}")
    prompt = JSON_PROMPT_TMPL.format(resume=resume_text[:18000])

    logger.debug("Using generation config: %s", GENERATION_CONFIG)
    logger.debug("Using safety settings: %s", SAFETY_SETTINGS)
    
    logger.info("Sending request to Gemini API")
    try:
        # Attempt API call with timeouts and proper error handling
        max_retries = 3
        retry_count = 0
        while True:
            try:
                response = model.generate_content(
                    contents=prompt,
                    safety_settings=SAFETY_SETTINGS,
                    generation_config=GENERATION_CONFIG
                )
                break  # Success, exit the retry loop
            except google_exceptions.PermissionDenied as e:
                raise APIConfigError(f"API key permissions error: {str(e)}")
            except google_exceptions.InvalidArgument as e:
                raise APIConfigError(f"Invalid API request: {str(e)}")
            except google_exceptions.ResourceExhausted as e:
                retry_count += 1
                if retry_count > max_retries:
                    raise APIConfigError(f"Max retries exceeded after rate limit: {str(e)}")
                
                # Parse retry delay from error message if available
                retry_delay = MIN_RETRY_DELAY
                if "retry_delay" in str(e):
                    try:
                        delay_str = str(e).split("retry_delay")[1].split("seconds:")[1].split("}")[0].strip()
                        retry_delay = min(float(delay_str), MAX_RETRY_DELAY)
                    except:
                        pass
                
                logger.warning(f"API quota exceeded (attempt {retry_count}/{max_retries}), waiting {retry_delay} seconds: %s", str(e))
                time.sleep(retry_delay)
                continue
                
            except Exception as e:
                raise APIConfigError(f"API request failed: {str(e)}")

        if not response:
            raise ParsingError("Empty response from API")
            
        logger.info("Received response from Gemini API")
        
        try:
            content = response.text
            if not content:
                raise ParsingError("Empty text in API response")
            logger.debug("Raw response: %s", content)
        except AttributeError as e:
            raise ParsingError(f"Malformed API response - no text attribute: {str(e)}")

        # Clean common surrounding delimiters (```json ... ```), then extract JSON
        logger.info("Cleaning and parsing response")
        try:
            # Remove code fences and clean response
            content = re.sub(r"^```(?:json)?\s*", "", content)
            content = re.sub(r"\s*```$", "", content)
            content = content.strip()
            
            if not content:
                raise ParsingError("Model returned empty content after cleaning")
            
            # Try to parse the JSON payload robustly
            parsed = _extract_json(content)
            logger.info("Successfully parsed JSON response")
            logger.debug("Parsed response: %s", parsed)
            
            # Validate JSON structure and types
            validate_parsed_json(parsed)
            logger.info("JSON validation passed")
            
        except (ParsingError, json.JSONDecodeError) as e:
            error_msg = f"Failed to parse response as JSON: {str(e)}"
            logger.error(error_msg)
            logger.debug("Raw content causing error: %s", content)
            raise ParsingError(error_msg)
        except ValidationError as e:
            error_msg = f"JSON validation failed: {str(e)}"
            logger.error(error_msg)
            logger.debug("Invalid JSON structure: %s", parsed)
            raise
        
    except ResumeParsing:
        # Let our custom exceptions propagate
        raise
    except Exception as e:
        error_msg = f"Unexpected error processing resume: {str(e)}"
        logger.error(error_msg, exc_info=True)
        raise ParsingError(error_msg)
    # Define required fields for normalization
    required_fields = ["name", "email", "phone", "skills", "exp_years", 
                      "current_location", "salary", "notice_period"]
    
    # Fill missing keys and normalize values
    missing_keys = [k for k in required_fields if k not in parsed]
    if missing_keys:
        logger.warning(f"Missing required keys: {missing_keys}")
        
    # Initialize with empty values for missing keys
    for k in required_fields:
        if k not in parsed:
            parsed[k] = "" if k != "exp_years" else 0
            logger.info(f"Initialized missing key '{k}' with default value")

    try:
        # Normalize and validate all fields
        normalized = {
            "name": (parsed.get("name") or "").strip(),
            "email": normalize_email(parsed.get("email")),
            "phone": normalize_phone(parsed.get("phone")),
            "skills": normalize_skills(parsed.get("skills")),
            "exp_years": to_int(parsed.get("exp_years"), 0),
            "current_location": (parsed.get("current_location") or "").strip(),
            "salary": (parsed.get("salary") or "").strip(),
            "notice_period": (parsed.get("notice_period") or "").strip()
        }
        
        # Log any significant normalizations
        for k, v in normalized.items():
            if str(v) != str(parsed.get(k, "")):
                logger.info(f"Normalized {k}: '{parsed.get(k, '')}' -> '{v}'")
                
        logger.info(f"Successfully normalized all fields")
        return normalized
        
    except Exception as e:
        error_msg = f"Failed to normalize parsed data: {str(e)}"
        logger.error(error_msg)
        raise ValidationError(error_msg)
